# me50
At first, i started the neural network with convotional layer with 32 filter in 3x3 grid and max pooling in 2x2 with a single layer of 128 node with .5 dropout by this i get .0562 accuracy the i started to increase the hidden layer as well as nodes in it after twwo or three combination accuracy increased to .4958 when i have tried 2 hidden layer with 128 node each after that i started testing with number of filter after 5 and 6 combination i get .8942 accuracy with 3 hidden layer of 1024 node each wit 32 filter. Now i have started with increased number of convotinal layer with previous combination and started the changeing the number of nodes more widely rather than power of 2 the i get accuracy of .9427 finally i found that swish is more reliable than relu activation function so changed all activation function with swish than i get the maximum accuracy of .9654 it is varying accuracy between .94 to .96
